# Pr√©diction de M√©dailles avec un Arbre de D√©cision üèÖ

## Description du Projet üìñ

Ce projet utilise un **arbre de d√©cision** pour pr√©dire si un athl√®te remportera une m√©daille ou non, bas√© sur des donn√©es d√©mographiques comme l'√¢ge et le genre. Le mod√®le permet d'identifier des crit√®res significatifs qui influencent les performances des athl√®tes.

Le projet suit plusieurs √©tapes essentielles, notamment :

- **Pr√©traitement des donn√©es** : Nettoyage et pr√©paration des donn√©es pour les rendre exploitables.
- **Construction d'un mod√®le pr√©dictif** : Utilisation d'un arbre de d√©cision pour analyser les variables influentes.
- **Visualisation des r√©sultats** : Cr√©ation d'une visualisation claire et interpr√©table de l'arbre de d√©cision.

---

## Fonctionnalit√©s principales üöÄ

### Pr√©traitement des donn√©es üßπ

1. **Conversion des variables cat√©goriques :**

   - La colonne `gender` a √©t√© transform√©e en valeurs num√©riques :
     - `0` pour les hommes.
     - `1` pour les femmes.

2. **Calcul de l'√¢ge :**

   - L'√¢ge des athl√®tes a √©t√© calcul√© automatiquement √† partir de leur date de naissance (`birth_date`).
   - Les lignes contenant des dates invalides ou manquantes ont √©t√© supprim√©es.

3. **Gestion des valeurs manquantes :**
   - Les observations sans √¢ge ou avec des valeurs manquantes dans d'autres colonnes importantes ont √©t√© supprim√©es.
   - **Nombre total de lignes supprim√©es :** Calcul√© et affich√© pour documenter la qualit√© du nettoyage des donn√©es.

### Construction d'un arbre de d√©cision üå≥

- **Biblioth√®que utilis√©e :**
  - Le mod√®le est construit √† l'aide de `DecisionTreeClassifier` de la biblioth√®que Scikit-learn.
- **Crit√®res utilis√©s pour la pr√©diction :**

  - `age` : L'√¢ge des athl√®tes, qui est la variable la plus influente.
  - `gender` : Le genre des athl√®tes, avec des interactions sp√©cifiques influen√ßant les performances.

- **Profondeur de l'arbre :**

  - L'arbre de d√©cision est limit√© √† une profondeur maximale de 5 pour √©viter le surapprentissage tout en conservant une interpr√©tabilit√© optimale.

- **Variable cible :**
  - `is_medallist` : Indique si un athl√®te a remport√© une m√©daille (`1`) ou non (`0`).

### Visualisation et export üì∑

- **Visualisation de l'arbre :**

  - L'arbre de d√©cision est affich√© avec des n≈ìuds color√©s pour indiquer la classe pr√©dite (`Medal` ou `No Medal`) et les informations telles que :
    - Les r√®gles de s√©paration (`age <=`, `gender =`, etc.).
    - La puret√© de chaque n≈ìud (indice de Gini).
    - Le nombre d'√©chantillons dans chaque groupe (`samples`).
    - Les pr√©dictions de classe (`class`).

- **Exportation :**
  - La visualisation est export√©e sous forme d'image haute r√©solution au format **JPG**.

---

## R√©sultats obtenus üìä

### Crit√®res d√©cisifs üßê

- L'analyse a montr√© que :
  - L'√¢ge est la **variable la plus influente** pour pr√©dire les chances de remporter une m√©daille.
  - Le genre joue √©galement un r√¥le important mais intervient principalement en combinaison avec l'√¢ge.

### Interpr√©tation de l'arbre üåü

- **Athl√®tes √¢g√©s (> 45,5 ans) :**
  - Ces athl√®tes ont une probabilit√© faible de remporter une m√©daille, ce qui est souvent li√© aux exigences physiques des comp√©titions.
- **Jeunes athl√®tes (√¢g√©s de 16,5 ans ou moins) :**
  - Les jeunes athl√®tes combin√©s √† d'autres caract√©ristiques (comme le genre) peuvent √©galement avoir des chances plus faibles de remporter une m√©daille.
- **Groupes sp√©cifiques :**
  - L'arbre r√©v√®le des combinaisons particuli√®res o√π certains sous-groupes, en fonction de leur √¢ge et de leur genre, ont des probabilit√©s √©lev√©es ou faibles de gagner une m√©daille.

### Visualisation des r√©sultats :

L'arbre montre des s√©parations claires et facilement interpr√©tables, avec des d√©cisions bas√©es principalement sur l'√¢ge et le genre.

---

## Am√©liorations possibles üîß

### Optimisation des hyperparam√®tres :

- Ajuster des param√®tres comme :
  - La **profondeur maximale** (`max_depth`) de l'arbre.
  - Le **nombre minimum d'√©chantillons** n√©cessaires pour une division (`min_samples_split`).
- Cela pourrait permettre d'am√©liorer la pr√©cision tout en √©vitant le surapprentissage.

### Enrichissement des donn√©es :

- Ajouter des variables suppl√©mentaires pour capturer davantage de facteurs influents, par exemple :
  - Le type de sport ou discipline (`event` ou `discipline`).
  - Le pays d'origine (`country`) pour repr√©senter les diff√©rences culturelles et structurelles.
  - Les performances pass√©es ou l'exp√©rience des athl√®tes.

### Validation crois√©e :

- Mettre en ≈ìuvre une validation crois√©e pour √©valuer la robustesse du mod√®le sur plusieurs sous-ensembles des donn√©es.

### Analyse de l'√©quilibre des classes :

- Si le jeu de donn√©es est d√©s√©quilibr√© (beaucoup plus de "No Medal" que de "Medal"), des techniques comme :
  - **Sur-√©chantillonnage** des classes minoritaires.
  - **Pond√©ration des classes** dans le mod√®le.
  - Ces approches pourraient am√©liorer les pr√©dictions pour les cas minoritaires (m√©daille).

---

## Technologies utilis√©es üõ†Ô∏è

- **Python** : Langage de programmation principal.
- **Biblioth√®ques Python :**
  - `pandas` pour la manipulation des donn√©es.
  - `scikit-learn` pour la construction du mod√®le et l'arbre de d√©cision.
  - `matplotlib` pour la visualisation de l'arbre.

---

## Installation et Ex√©cution üñ•Ô∏è

1. **Cloner le projet :**

   ```bash
   git clone https://github.com/votre_utilisateur/decision-tree-medals.git
   cd decision-tree-medals
   ```

2. **Installez les d√©pendances Python :**

```bash
pip install pandas matplotlib scikit-learn
```

## Auteur ‚úçÔ∏è

Nom : BENMAMMAR HOUSSAM
GitHub : HoussemBenmammar

## Licence üìú

Vous pouvez directement copier ce contenu dans votre fichier `README.md`. Si vous avez des questions ou souhaitez des ajustements, n'h√©sitez pas ! üòä
